{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uglCgVhsWiV-"
      },
      "source": [
        "# Step 1 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psxbLRsqWSlx",
        "outputId": "04131d5e-0d2c-4c01-8d35-b9459e6f1798"
      },
      "outputs": [],
      "source": [
        "!pip install pycoingecko requests tiktoken cohere openai pinecone-client langchain apify-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HR1H9tt4KYh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
        "os.environ[\"APIFY_API_TOKEN\"]   = \"APIFY_API_KEY\"\n",
        "os.environ[\"PINECONE_API_KEY\"]  = 'PINECONE_API_KEY'\n",
        "os.environ[\"PINECONE_ENV\"]      = 'PINECONE_ENV' #gcp-starter\n",
        "os.environ[\"INDEX_NAME\"]        = 'INDEX_NAME'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgYxuB8pWvQ3"
      },
      "source": [
        "# Step 2 - Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csnX63HhWwyR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime as dt\n",
        "import openai\n",
        "import re\n",
        "import time\n",
        "import pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8TgziWYXJgb"
      },
      "source": [
        "### Data Source 1/2: APIFY Google Search Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roxhQvf9w5Cm"
      },
      "outputs": [],
      "source": [
        "from apify_client import ApifyClient\n",
        "\n",
        "# Initialize the ApifyClient with your API token\n",
        "client = ApifyClient(os.getenv(\"APIFY_API_KEY\"))\n",
        "\n",
        "# Prepare the Actor input\n",
        "run_input = {\n",
        "    \"queries\": \"gartner semiconductor\",\n",
        "    \"maxPagesPerQuery\": 1,\n",
        "    \"resultsPerPage\": 100,\n",
        "    \"customDataFunction\": \"\"\"async ({ input, $, request, response, html }) => {\n",
        "  return {\n",
        "    pageTitle: $('title').text(),\n",
        "  };\n",
        "};\"\"\",\n",
        "}\n",
        "\n",
        "# Run the Actor and wait for it to finish\n",
        "run = client.actor(\"apify/google-search-scraper\").call(run_input=run_input)\n",
        "\n",
        "# Fetch and print Actor results from the run's dataset (if there are any)\n",
        "loader = client.dataset(run[\"defaultDatasetId\"]).iterate_items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1-J_SwUVyZv",
        "outputId": "8bf42427-cf29-48a3-9ae9-84b7a0d3fd22"
      },
      "outputs": [],
      "source": [
        "temp = list()\n",
        "results = list()\n",
        "\n",
        "for i in loader:\n",
        "  temp.append(i)\n",
        "\n",
        "print(temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUaSkPaw0sj-"
      },
      "outputs": [],
      "source": [
        "data = temp[0]['organicResults']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIWeI5gn1q9J"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqsnRvr91VGj"
      },
      "outputs": [],
      "source": [
        "#2023년 데이터\n",
        "filtered_data = [item for item in data if 'date' in item and datetime.fromisoformat(item['date'][:-1]).year == 2023]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a-9bCCOaqOI"
      },
      "outputs": [],
      "source": [
        "urls = []\n",
        "\n",
        "for item in filtered_data:\n",
        "  urls.append(item['url'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C8oH_Zv-AeV"
      },
      "source": [
        "###APIFY Web Contents Crawling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAo0JZIGPt6d"
      },
      "outputs": [],
      "source": [
        "from langchain.utilities import ApifyWrapper\n",
        "from langchain.document_loaders.base import Document\n",
        "import os\n",
        "\n",
        "\n",
        "# Initialize the ApifyClient with your API token\n",
        "apify = ApifyWrapper()\n",
        "\n",
        "startUrls = [{\"url\": url} for url in urls]\n",
        "\n",
        "#print(startUrls)\n",
        "\n",
        "# Prepare the Actor input\n",
        "run_input = {\n",
        "    \"startUrls\": startUrls,\n",
        "    \"includeUrlGlobs\": [],\n",
        "    \"excludeUrlGlobs\": [],\n",
        "    \"initialCookies\": [],\n",
        "    \"proxyConfiguration\": { \"useApifyProxy\": True },\n",
        "    \"removeElementsCssSelector\": \"\"\"nav, footer, script, style, noscript, svg,\n",
        "[role=\\\"alert\\\"],\n",
        "[role=\\\"banner\\\"],\n",
        "[role=\\\"dialog\\\"],\n",
        "[role=\\\"alertdialog\\\"],\n",
        "[role=\\\"region\\\"][aria-label*=\\\"skip\\\" i],\n",
        "[aria-modal=\\\"true\\\"]\"\"\",\n",
        "    \"clickElementsCssSelector\": \"[aria-expanded=\\\"false\\\"]\",\n",
        "}\n",
        "\n",
        "# Run the Actor and wait for it to finish\n",
        "loader = apify.call_actor(\n",
        "    actor_id=\"apify/website-content-crawler\",\n",
        "    run_input=run_input,\n",
        "    dataset_mapping_function=lambda item: Document(\n",
        "        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS3ABLkDefCJ"
      },
      "source": [
        "### Data Source 2/2 - Pinecone Initialize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr3f04dUMfLL"
      },
      "source": [
        "###Pinecone Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giX7LFfB4VEE"
      },
      "outputs": [],
      "source": [
        "#INIT PINECONE\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "# find your environment next to the api key in pinecone console\n",
        "env = os.getenv(\"PINECONE_ENV\")\n",
        "# index name\n",
        "index_name = os.getenv(\"INDEX_NAME\")\n",
        "\n",
        "pinecone.init(api_key=api_key, environment=env)\n",
        "pinecone.whoami()\n",
        "\n",
        "import time\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    # if does not exist, create index\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=1536, #huggingface:768 openai:1536\n",
        "        metric='cosine'\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pinecone.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tt3PdwP3tCU",
        "outputId": "a5682c0c-b59f-4c06-8040-8864c3fce60a"
      },
      "outputs": [],
      "source": [
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jCj3Zz574rp"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTBP9BZzBdsw"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iPjp1ZYJHVq"
      },
      "source": [
        "#벡터 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wibreGX0r0ew"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GOWDhNetqfP"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "docs = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHryTBzpxyJ1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# Embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        "    add_start_index = True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZLo5HRMP4Bk"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "documents = text_splitter.split_documents(docs)\n",
        "\n",
        "# Create embeddings and store in vectordb\n",
        "docsearch = Pinecone.from_documents(documents, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkm4G4-zQuSd",
        "outputId": "c7cd8683-342a-434f-d0a2-215f1fde3e2b"
      },
      "outputs": [],
      "source": [
        "index_name = os.getenv(\"INDEX_NAME\")\n",
        "\n",
        "# Define retriever\n",
        "import pinecone\n",
        "\n",
        "index = pinecone.Index(index_name)\n",
        "vectorstore = Pinecone(index, embeddings.embed_query, \"text\")\n",
        "\n",
        "# Define retriever\n",
        "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z30qPau0Q-rY"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T_wMVzKQ-rZ"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model='gpt-3.5-turbo-16k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT7FznPkQ-rZ"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "SYSTEM\n",
        "You are an expert researcher and writer, tasked with answering any question.\n",
        "Generate a comprehensive and informative, yet concise answer of 250 words or less for the given question based solely on the provided search results (URL and content).\n",
        "You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer.\n",
        "Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately.\n",
        "Place these citations at the end of the sentence or paragraph that reference them - do not put them all at the end.\n",
        "If different results refer to different entities within the same name, write separate answers for each entity.\n",
        "If you want to cite multiple results for the same sentence, format it as `[${{number1}}] [${{number2}}]`.\n",
        "However, you should NEVER do this with the same number - if you want to cite `number1` multiple times for a sentence, only do `[${{number1}}]` not `[${{number1}}] [${{number1}}]`\n",
        "You should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end.\n",
        "If there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
        "Anything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n",
        "You must answer in Korean.\n",
        "\n",
        "<context>\n",
        "    {context}\n",
        "<context/>\n",
        "\n",
        "HUMAN\n",
        "{question}\n",
        "  \"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO_Cf66aQ-rZ"
      },
      "outputs": [],
      "source": [
        "retrieval_chain = (\n",
        "      {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "      | prompt\n",
        "      | model\n",
        "      | StrOutputParser()\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Txx-yrmQQ-rZ",
        "outputId": "a4af9671-91a2-4086-f9d6-7773a15bd852"
      },
      "outputs": [],
      "source": [
        "retrieval_chain.invoke(\"I want to know Gartner's predictions for the semiconductor industry.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
