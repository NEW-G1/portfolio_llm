{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psxbLRsqWSlx",
        "outputId": "1681e1bb-3cbf-4625-db0f-37f21fbcacb6"
      },
      "outputs": [],
      "source": [
        "!pip install pycoingecko requests tiktoken cohere openai pinecone-client langchain apify-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIB6YLzGHh0g"
      },
      "source": [
        "###1.IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csnX63HhWwyR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders.base import Document\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.utilities import ApifyWrapper\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Vectara\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n520zBIcHwhS"
      },
      "source": [
        "###2.KEY SETTINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HR1H9tt4KYh"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]      = \"OPENAI_API_KEY\"\n",
        "os.environ[\"VECTARA_CUSTOMER_ID\"] = \"VECTARA_CUSTOMER_ID\"\n",
        "os.environ[\"VECTARA_CORPUS_ID\"]   = \"VECTARA_CORPUS_ID\"\n",
        "os.environ[\"VECTARA_API_KEY\"]     = \"VECTARA_API_KEY\"\n",
        "os.environ[\"APIFY_API_TOKEN\"]   = \"APIFY_API_TOKEN\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgYxuB8pWvQ3"
      },
      "source": [
        "##3.Import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8TgziWYXJgb"
      },
      "source": [
        "###3.Data Source: APIFY Google Search Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MLbu_UOIC1U"
      },
      "outputs": [],
      "source": [
        "queries = \"semiconductor forecast gartner\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roxhQvf9w5Cm"
      },
      "outputs": [],
      "source": [
        "from apify_client import ApifyClient\n",
        "# Initialize the ApifyClient with your API token\n",
        "client = ApifyClient(os.getenv(\"APIFY_API_TOKEN\"))\n",
        "\n",
        "# Prepare the Actor input\n",
        "run_input = {\n",
        "    \"queries\": queries,\n",
        "    \"maxPagesPerQuery\": 1,\n",
        "    \"resultsPerPage\": 100,\n",
        "    \"customDataFunction\": \"\"\"async ({ input, $, request, response, html }) => {\n",
        "  return {\n",
        "    pageTitle: $('title').text(),\n",
        "  };\n",
        "};\"\"\",\n",
        "}\n",
        "\n",
        "# Run the Actor and wait for it to finish\n",
        "run = client.actor(\"apify/google-search-scraper\").call(run_input=run_input)\n",
        "\n",
        "# Fetch and print Actor results from the run's dataset (if there are any)\n",
        "loader = client.dataset(run[\"defaultDatasetId\"]).iterate_items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1-J_SwUVyZv",
        "outputId": "fc1b6834-42ac-45c5-b128-0609c0aa8400"
      },
      "outputs": [],
      "source": [
        "temp = list()\n",
        "results = list()\n",
        "\n",
        "for i in loader:\n",
        "  temp.append(i)\n",
        "\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUaSkPaw0sj-"
      },
      "outputs": [],
      "source": [
        "data = temp[0]['organicResults']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqsnRvr91VGj"
      },
      "outputs": [],
      "source": [
        "#2023년 데이터만 \n",
        "filtered_data = [item for item in data if 'date' in item and datetime.fromisoformat(item['date'][:-1]).year == 2023]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a-9bCCOaqOI"
      },
      "outputs": [],
      "source": [
        "urls = []\n",
        "\n",
        "for item in filtered_data:\n",
        "  urls.append(item['url'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnlrWixbIjyC"
      },
      "source": [
        "###APIFY Google Search Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g81ytXpgseyK",
        "outputId": "2c26b233-500f-46e0-9fab-00f4782b3cdf"
      },
      "outputs": [],
      "source": [
        "urls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uZcWRzoDY78"
      },
      "source": [
        "###4.INITIALIZE VECTARA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBoARJU1DTNW"
      },
      "outputs": [],
      "source": [
        "vectara = Vectara(\n",
        "    vectara_customer_id = os.getenv(\"VECTARA_CUSTOMER_ID\"),\n",
        "    vectara_corpus_id   = os.getenv(\"VECTARA_CORPUS_ID\"),\n",
        "    vectara_api_key     = os.getenv(\"VECTARA_API_KEY\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-h1VXN-SP8U"
      },
      "source": [
        "#Google Search Result[APIFY] - WebContents Crawler[APIFY] - CHATGPT - VECTARA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C8oH_Zv-AeV"
      },
      "source": [
        "###5.APIFY Web Contents Crawling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAo0JZIGPt6d"
      },
      "outputs": [],
      "source": [
        "# Initialize the ApifyClient with your API token\n",
        "apify = ApifyWrapper()\n",
        "\n",
        "startUrls = [{\"url\": url} for url in urls]\n",
        "\n",
        "#print(startUrls)\n",
        "\n",
        "# Prepare the Actor input\n",
        "run_input = {\n",
        "    \"startUrls\": startUrls,\n",
        "    \"includeUrlGlobs\": [],\n",
        "    \"excludeUrlGlobs\": [],\n",
        "    \"initialCookies\": [],\n",
        "    \"proxyConfiguration\": { \"useApifyProxy\": True },\n",
        "    \"removeElementsCssSelector\": \"\"\"nav, footer, script, style, noscript, svg,\n",
        "[role=\\\"alert\\\"],\n",
        "[role=\\\"banner\\\"],\n",
        "[role=\\\"dialog\\\"],\n",
        "[role=\\\"alertdialog\\\"],\n",
        "[role=\\\"region\\\"][aria-label*=\\\"skip\\\" i],\n",
        "[aria-modal=\\\"true\\\"]\"\"\",\n",
        "    \"clickElementsCssSelector\": \"[aria-expanded=\\\"false\\\"]\",\n",
        "}\n",
        "\n",
        "# Run the Actor and wait for it to finish\n",
        "loader = apify.call_actor(\n",
        "    actor_id=\"apify/website-content-crawler\",\n",
        "    run_input=run_input,\n",
        "    dataset_mapping_function=lambda item: Document(\n",
        "        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wibreGX0r0ew"
      },
      "outputs": [],
      "source": [
        "#LLM Setting\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWS3fcjO-W23"
      },
      "outputs": [],
      "source": [
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJTqZl-FBkOu"
      },
      "source": [
        "###6.VECTARA DATA 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rwafr7yU-d-j"
      },
      "outputs": [],
      "source": [
        "vectorstore = Vectara.from_documents(documents, embedding=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKAj8ZBAHCNq"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIiv0brl7fav"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(lambda_val=0.025, k=5, filter=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T_wMVzKQ-rZ"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model='gpt-3.5-turbo-16k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT7FznPkQ-rZ"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "SYSTEM\n",
        "You are an expert researcher and writer, tasked with answering any question.\n",
        "Generate a comprehensive and informative, yet concise answer of 250 words or less for the given question based solely on the provided search results (URL and content).\n",
        "You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer.\n",
        "Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately.\n",
        "Place these citations at the end of the sentence or paragraph that reference them - do not put them all at the end.\n",
        "If different results refer to different entities within the same name, write separate answers for each entity.\n",
        "If you want to cite multiple results for the same sentence, format it as `[${{number1}}] [${{number2}}]`.\n",
        "However, you should NEVER do this with the same number - if you want to cite `number1` multiple times for a sentence, only do `[${{number1}}]` not `[${{number1}}] [${{number1}}]`\n",
        "You should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end.\n",
        "If there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
        "Anything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n",
        "You must answer in Korean.\n",
        "\n",
        "<context>\n",
        "    {context}\n",
        "<context/>\n",
        "\n",
        "HUMAN\n",
        "{question}\n",
        "  \"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO_Cf66aQ-rZ"
      },
      "outputs": [],
      "source": [
        "retrieval_chain = (\n",
        "      {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "      | prompt\n",
        "      | llm\n",
        "      | StrOutputParser()\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Txx-yrmQQ-rZ",
        "outputId": "0eac5331-f1e8-43dd-ea56-1dad91e67ddf"
      },
      "outputs": [],
      "source": [
        "retrieval_chain.invoke(\"가트너 뉴스 기준으로 2024년 반도체 시장 현황 및 전망이 알고싶어요\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
