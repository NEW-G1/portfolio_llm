{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLXwpvf1ZxCR",
        "outputId": "79fc87a3-5a98-43ef-cb9a-de138574eda0"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36Rl2D29aQoI",
        "outputId": "21729988-e156-47c8-c806-d93688333b28"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emJPFOtxaZ0C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6FLiPDubCd4"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG5UsUIsbF-4"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HpYBk1bK_Z",
        "outputId": "ee5a4437-4e30-4706-af37-0d3fd6825feb"
      },
      "outputs": [],
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "print(llm(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbdmKGSLbTO8"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQpBNhslbYAl",
        "outputId": "e8f44766-6cf3-483c-aa06-a9af0a6bb968"
      },
      "outputs": [],
      "source": [
        "print(prompt.format(product=\"colorful socks\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8R-a6KUcX5K"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46wmsh3IceOF"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bLHiaXVSchiN",
        "outputId": "b1b62eda-26ee-441f-fe77-7d3deb875af6"
      },
      "outputs": [],
      "source": [
        "chain.run(\"colorful socks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llokZLOSe73A",
        "outputId": "b302cbdc-6b4c-41cb-9707-804f8d63d603"
      },
      "outputs": [],
      "source": [
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4_6JtKoe_Rt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"SERP_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "eyo6PmDhfLaB",
        "outputId": "d7edc5c4-1ded-4f49-f329-e471654b48b6"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# First, let's load the language model we're going to use to control the agent.\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Now let's test it out!\n",
        "agent.run(\"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "wTZoX0zke5u3",
        "outputId": "fc92adac-1531-4e40-c1b4-b1fc611d412b"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "conversation = ConversationChain(llm=llm, verbose=True)\n",
        "\n",
        "conversation.predict(input=\"Hi there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HZ0o-phVg8KU",
        "outputId": "7fed6bb7-92e3-47c6-d729-c9a7ac1071c4"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVDv9kHChKpt"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUaX3NEwhRd7",
        "outputId": "744ae0dc-7896-48a0-8552-8a8acd4abf74"
      },
      "outputs": [],
      "source": [
        "chat([HumanMessage(content=\"Translate this sentence from English to Korean. I love programming.\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaW-BzVJhdm9",
        "outputId": "a8308a12-cd47-48f9-ad99-28193dfce303"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that translates English to Chinese.\"),\n",
        "    HumanMessage(content=\"I love programming.\")\n",
        "]\n",
        "chat(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EGyJ07rhvAx"
      },
      "outputs": [],
      "source": [
        "batch_messages = [\n",
        "    [\n",
        "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
        "        HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
        "    ],\n",
        "    [\n",
        "        SystemMessage(content=\"You are a helpful assistant that translates English to Korean.\"),\n",
        "        HumanMessage(content=\"Translate this sentence from English to Korean. I love artificial intelligence.\")\n",
        "    ],\n",
        "]\n",
        "result = chat.generate(batch_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRaiAVPohxNE",
        "outputId": "dcef1d39-7fe4-4937-efa1-649e26673d6e"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDsq2M_Kh67V",
        "outputId": "a8768adf-ae22-4fa9-9d26-830f79c88686"
      },
      "outputs": [],
      "source": [
        "result.llm_output['token_usage']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv3owbRhiTZT",
        "outputId": "dc8533f9-d0da-429a-f17e-dd03dcdeefb1"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(temperature=0)\n",
        "\n",
        "template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "# get a chat completion from the formatted messages\n",
        "chat(chat_prompt.format_prompt(input_language=\"English\", output_language=\"French\", text=\"I love programming.\").to_messages())\n",
        "# -> AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xEtPPQ14i7BT",
        "outputId": "213a1ca6-ab50-4539-9731-0a378e78538e"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(temperature=0)\n",
        "\n",
        "template=\"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
        "chain.run(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")\n",
        "# -> \"J'aime programmer.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xEe94HcjYFP"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# First, let's load the language model we're going to use to control the agent.\n",
        "chat = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
        "llm = OpenAI(temperature=0)\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, chat, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "gtOaP02xjyAn",
        "outputId": "1425d667-1fe4-4b9d-efaa-b7fa985bf38e"
      },
      "outputs": [],
      "source": [
        "# Now let's test it out!\n",
        "agent.run(\"현재 대한민국 대통령은 누구인가? \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "TJzZZqZHk7jC",
        "outputId": "7e1c45d0-a208-40ae-e3d8-76c0f5f16404"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "])\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)\n",
        "\n",
        "conversation.predict(input=\"Hi there!\")\n",
        "# -> 'Hello! How can I assist you today?'\n",
        "\n",
        "\n",
        "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")\n",
        "# -> \"That sounds like fun! I'm happy to chat with you. Is there anything specific you'd like to talk about?\"\n",
        "\n",
        "conversation.predict(input=\"Tell me about yourself.\")\n",
        "# -> \"Sure! I am an AI language model created by OpenAI. I was trained on a large dataset of text from the internet, which allows me to understand and generate human-like language. I can answer questions, provide information, and even have conversations like this one. Is there anything else you'd like to know about me?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfRQuCtGXDYy",
        "outputId": "2f1cf9d3-8508-4ec7-9f0f-f472e3f4af45"
      },
      "outputs": [],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvR5ovvv6ggj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhr58gI-Auu_"
      },
      "source": [
        "https://www.mysqltutorial.org/mysql-sample-database.aspx\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=117Q8ANEP35cnY8pEYhaXJAL7z1XniZgy\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otqAmUdLXKVl",
        "outputId": "4ac9040a-6df8-43ae-e90c-51a3348d0b57"
      },
      "outputs": [],
      "source": [
        "!apt-get install sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuxO8c6WYsRX",
        "outputId": "7f76f4ac-b15c-4ca1-a70d-13710ae6b187"
      },
      "outputs": [],
      "source": [
        "!wget \"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\" -O \"chinook.zip\"\n",
        "!unzip -o -q \"chinook.zip\" -d \"chinook_db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g0GTy2GYzHc",
        "outputId": "d6c9200c-23fc-4662-b991-a59466cffb48"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnjdKyVyXdR0",
        "outputId": "82e63014-291d-4b0e-c222-f704ebf7b55e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.path.isfile('/content/chinook_db/chinook.db'):\n",
        "    print('Chinook database file exists')\n",
        "else:\n",
        "    print('Chinook database file does not exist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1GiLgrTuC8k"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# 데이터베이스 파일 경로\n",
        "db_path = '/content/chinook_db/chinook.db'\n",
        "\n",
        "# 데이터베이스 연결\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLh7pNq1uliW",
        "outputId": "303847d7-1360-471d-a877-740791fc003b"
      },
      "outputs": [],
      "source": [
        "# 쿼리 실행\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM sqlite_master;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMsfJH9Ow7_e",
        "outputId": "e6eab1e3-f149-4266-ea48-876b6fbea9c8"
      },
      "outputs": [],
      "source": [
        "cursor = conn.cursor()\n",
        "cursor.execute(\"select count(*) from employees\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJHIdRS0u3IL",
        "outputId": "dec63649-d8bd-466c-d85e-b11121381cfa"
      },
      "outputs": [],
      "source": [
        "# 결과 출력\n",
        "results = cursor.fetchall()\n",
        "for row in results:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFmpqzaqu7fT"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt2qQHCkQJG1"
      },
      "outputs": [],
      "source": [
        "from langchain import SQLDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq7vg8O2QOn5"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.llms.openai import OpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCJZgUR-nnRN"
      },
      "outputs": [],
      "source": [
        "#확인중\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "#from langchain_experimental.sql import SQLDatabaseChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOsJqf1uwXUU"
      },
      "outputs": [],
      "source": [
        "db = SQLDatabase.from_uri(\"sqlite:////content/chinook_db/chinook.db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgIgoTiYwoXW"
      },
      "outputs": [],
      "source": [
        "toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHT7I6a1wtU3"
      },
      "outputs": [],
      "source": [
        "agent_executor = create_sql_agent(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "3k-XP7P1Rz8C",
        "outputId": "afa6b6fb-5bf2-4d3f-c5bd-585e586663ae"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"Describe the playlisttrack table\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "gxwmdMS6opKM",
        "outputId": "8e1588cd-0996-4060-e986-9fdc1abe2bf3"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"How many albums does Aerosmith have? and what is album title?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "ITwJmkdH6xJc",
        "outputId": "c27dd554-af04-4876-b068-adbfed23ccb4"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"Find top 5 tracks with the highest unit prices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "oxbnV9EYwwHz",
        "outputId": "ebb3586f-4eab-4111-bf89-8f8cb78c3ed1"
      },
      "outputs": [],
      "source": [
        "agent_executor.run('단가가 가장 높은 상위 5개 트랙을 찾아줘.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "FRatCOm41nWZ",
        "outputId": "97a780cb-ea25-4b54-c71b-f9fd3ecd886e"
      },
      "outputs": [],
      "source": [
        "agent_executor.run('albums 데이터가 총 몇개냐?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "XC5M7dTs2GTX",
        "outputId": "84e85b74-b1b5-4244-8d4c-8713e9a0f0e4"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"aerosmith의 히트곡 4개만 알려줘\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5JZFO3rW3dKX",
        "outputId": "b0115d53-10bc-4687-fb54-8aa75e059dc0"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"cryin도 히트곡이 아닌가?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "clQNAr-E4ZfF",
        "outputId": "1585d860-b049-4f8a-c76c-e112e7c3a658"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"playlisttrack 테이블 설명좀 해줘\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gAP75mkM6jMr",
        "outputId": "3b69f61a-8edd-4a4b-a5b4-a951f353ad19"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"Show the total number of tracks in each playlist. The Playlist name should be included in the result.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "Jhho-EWz6vpO",
        "outputId": "ae027dd2-ec7c-482e-ba5e-92b6625257bb"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"각 재생 목록의 총 트랙 수를 표시합니다. 재생 목록 이름이 결과에 포함되어야 합니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R7vto2hB67Pj",
        "outputId": "f9901806-21f5-47d7-bcb2-179dc36e665b"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"Who are the top 3 best selling artists?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70jqko8KX7Gp",
        "outputId": "d957ab5f-7faf-448f-feed-6a5a336a2535"
      },
      "outputs": [],
      "source": [
        "!pip install pymssql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bLOlTe5YFk4"
      },
      "outputs": [],
      "source": [
        "database_user = 'DB USER'\n",
        "database_password = 'DB PASSWORD'\n",
        "database_server = 'DB Server'\n",
        "database_db = 'DB Name'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--GZsTYpoCL4"
      },
      "outputs": [],
      "source": [
        "import urllib.parse\n",
        "encoded_password = urllib.parse.quote(database_password)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHFdtR6aoBhY"
      },
      "outputs": [],
      "source": [
        "connection_string = f\"mssql+pymssql://{database_user}:{encoded_password}@{database_server}:1433/{database_db}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ynvwdz6FYhbx",
        "outputId": "7884e15c-4be0-4368-c9e6-8766fd7e91e5"
      },
      "outputs": [],
      "source": [
        "connection_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0Oyf5iqY5Ip"
      },
      "outputs": [],
      "source": [
        "#이거 한시간 걸림.\n",
        "db = SQLDatabase.from_uri(connection_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdQDshJkklcY"
      },
      "outputs": [],
      "source": [
        "toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_d-a5b1ksn7"
      },
      "outputs": [],
      "source": [
        "agent_executor = create_sql_agent(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "HWRMkQ8tkuNg",
        "outputId": "85bf1a31-9521-4781-8cae-ef1e47ba9899"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"what table do you have?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "UrRM0YIfp2kw",
        "outputId": "79e4f431-ce50-4e42-d406-3d12b328cb26"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"TB_DYN_INVENTORY_INSP에 데이터 몇건있냐?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "lVzXAb5QqMke",
        "outputId": "dfb179e7-ee4c-4424-f73a-521bc9ca553d"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(\"재고테이블에 데이터 몇건있냐?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JOMmWleScz8"
      },
      "source": [
        "### WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Jq2heQSp1w"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# used to create the memory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# used to load text\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "# used to create the retriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# used to create the retrieval tool\n",
        "from langchain.agents import tool\n",
        "\n",
        "# used to create the prompt template\n",
        "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.prompts import MessagesPlaceholder\n",
        "\n",
        "\n",
        "# used to create the agent executor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "\n",
        "from langchain.document_loaders import UnstructuredURLLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz03JSyFWI14",
        "outputId": "82e7f356-3a91-4252-e6d5-2d52ac2da4c5"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAZB1xYXWU_X",
        "outputId": "9e062684-30b3-4e9d-ecb1-3043c5113d8c"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "441I2--BS3cI"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "\n",
        "    data = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(data)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    return db\n",
        "\n",
        "db = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwyNyc_Gk4cw",
        "outputId": "9035817d-1d9e-4216-d18c-f492b27e5586"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtY61d1alk9A",
        "outputId": "62a0acc5-43ba-46b0-cc02-edeba1024097"
      },
      "outputs": [],
      "source": [
        "!pip install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5ylCQ5mklDJ"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\n",
        "]\n",
        "\n",
        "def url_load_data():\n",
        "    #loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "    loader = UnstructuredURLLoader(urls=urls)\n",
        "    data = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(data)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    return db\n",
        "\n",
        "db = url_load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jp16xomWdSO"
      },
      "outputs": [],
      "source": [
        "# instantiate the database retriever\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1vYGPuLWiOH"
      },
      "outputs": [],
      "source": [
        "# define the retriever tool\n",
        "@tool\n",
        "def tool(query):\n",
        "    \"Searches and returns documents regarding the llm powered autonomous agents blog\"\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    return docs\n",
        "\n",
        "tools = [tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXsdjtXJWrF_"
      },
      "outputs": [],
      "source": [
        "# define the prompt\n",
        "system_message = SystemMessage(\n",
        "        content=(\n",
        "            \"Do your best to answer the questions. \"\n",
        "            \"Feel free to use any tools available to look up \"\n",
        "            \"relevant information, only if neccessary\"\n",
        "        )\n",
        ")\n",
        "prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
        "        system_message=system_message\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwQcaEBUXB9e"
      },
      "outputs": [],
      "source": [
        "# instantiate the large language model\n",
        "llm = ChatOpenAI(temperature = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C_7i4sBXJzR"
      },
      "outputs": [],
      "source": [
        "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt_template)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools,  verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZWHBTn2XUOH",
        "outputId": "dbf3dd3d-d5d6-42c6-aca5-053b4db744b8"
      },
      "outputs": [],
      "source": [
        "response = agent_executor({\"input\": \"what is this blog?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYBXkygVXkNP",
        "outputId": "926f0357-2471-4311-ff6c-8a6a14902e3c"
      },
      "outputs": [],
      "source": [
        "response = agent_executor({\"input\": \"Please summarize the content of this blog.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxAdmvS4X8sG",
        "outputId": "9d5aba7b-873f-4031-c2b2-ef3955df9368"
      },
      "outputs": [],
      "source": [
        "response = agent_executor({\"input\": \"what is chain of thought?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p7GecTHnwG3",
        "outputId": "8c99e03f-025e-4452-c7d4-b0b8ae88b24c"
      },
      "outputs": [],
      "source": [
        "response = agent_executor({\"input\": \"What is prompt engineering? Please explain based on the blog.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE4ojrrDoApO",
        "outputId": "a1254beb-fa4a-4833-f0f2-b94756aaf605"
      },
      "outputs": [],
      "source": [
        "response = agent_executor({\"input\":\"Show me Tips for Example Selection,블로그에서 찾고 없으면 검색해서 결과보여줘\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
